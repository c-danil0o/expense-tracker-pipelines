version: "3.7"

services:

  cadvisor:
    container_name: cadvisor-mon
    image: gcr.io/cadvisor/cadvisor:v0.47.1
    network_mode: "host"
    ports:
      - "9091:9091"
    volumes:
      - "/:/rootfs"
      - "/var/run:/var/run"
      - "/sys:/sys"
      - "/var/lib/docker/:/var/lib/docker"
      - "/dev/disk/:/dev/disk"
    command:
      - '-port=9091'
    privileged: true
    devices:
      - "/dev/kmsg"

  spring-boot:
    build: ./tracker/
    restart: always
    ports:
      - 8085:8080
    networks:
      - springapimysql-net
    environment:
      MYSQL_HOST: mysqldb
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      DATABASE_USERNAME: ${DATABASE_USERNAME}
      EMAIL: ${EMAIL}
      EMAIL_CODE: ${EMAIL_CODE}
      SECRET_KEY: ${SECRET_KEY}
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      SCHEMA_REGISTRY_SERVER: schema-registry:8081
    depends_on:
      mysqldb:
        condition: service_healthy

  x-spark-common: &spark-common
    image: bitnami/spark:latest
    volumes:
      - ./airflow/jobs:/opt/bitnami/spark/jobs
    networks:
      - springapimysql-net
  spark-master:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.master.Master --webui-port 4040
    ports:
      - "4040:4040"
      - "7077:7077"
    networks:
      - springapimysql-net


  spark-worker:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

    networks:
      - springapimysql-net

  spark-worker2:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

    networks:
      - springapimysql-net

  x-airflow-common:
    &airflow-common
#    image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:latest}
    build: ./airflow/
    environment:
      &airflow-common-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/jobs:/opt/airflow/jobs
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
    networks:
      - springapimysql-net
    depends_on:
      postgres:
        condition: service_healthy
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    networks:
      - springapimysql-net
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 5s
      retries: 5
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    networks:
      - springapimysql-net
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always

  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}

#  consumer:
#    build: ../consumer/.
#    restart: always
#    ports:
#      - 8082:8082
#    networks:
#      - springapimysql-net
#    environment:
#      KAFKA_BOOTSTRAP_SERVER: broker:29092
#      SCHEMA_REGISTRY_SERVER: schema-registry:8081
#      MYSQL_HOST: mysqldb
#      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
#      DATABASE_USERNAME: ${DATABASE_USERNAME}
#    depends_on:
#      - broker
  broker:
    image: confluentinc/cp-kafka:latest
    container_name: broker
    ports:
      - 50012:50012
      - 29092:29092
    #  expose:
    #    - 9096
    networks:
      - springapimysql-net
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:9093,PLAINTEXT_HOST://broker:50012
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:50012
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 5
      CLUSTER_ID: 999

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "docker-connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "docker-connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "docker-connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_PORT: 8083
      CONNECT_PLUGIN_PATH: "/usr/share/java"
      CLASSPATH: /usr/share/java/kafka-connect-jdbc/mysql-connector-j-8.0.31.jar
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka=INFO,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
    volumes:
      - ./kafka-connect:/kafka-connect
      - ./drivers/mysql-connector-j-8.0.31.jar:/usr/share/java/kafka-connect-jdbc/mysql-connector-j-8.0.31.jar
      - ./kafka/confluentinc-kafka-connect-jdbc-10.8.0:/usr/share/java/confluentinc-kafka-connect-jdbc-10.8.0
    depends_on:
      - broker
    networks:
      - springapimysql-net

  schema-registry:
    image: bitnami/schema-registry
    ports:
      - "8081:8081"
    depends_on:
      - broker
    environment:
      - SCHEMA_REGISTRY_KAFKA_BROKERS=PLAINTEXT://broker:29092
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081
      - plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors
    networks:
      - springapimysql-net
  mysqldb:
    image: "mysql:8.0"
    restart: always
    ports:
      - 3307:3306
    expose:
      - 3307
    networks:
      - springapimysql-net
    volumes:
      - my-db:/var/lib/mysql
    environment:
      MYSQL_USER: user
      MYSQL_PASSWORD: password
      MYSQL_ROOT_PASSWORD: root
    healthcheck:
      test: [ "CMD-SHELL", "/usr/bin/mysql --user=user --password=password --execute \"SHOW DATABASES;\"" ]
      interval: 10s
      timeout: 10s
      retries: 10
  grafana:
    image: grafana/grafana-enterprise
    restart: unless-stopped
    networks:
      - springapimysql-net
    ports:
      - '3000:3000'
    volumes:
      - 'grafana_storage:/var/lib/grafana'

networks:
  springapimysql-net:

volumes:
  my-db:
  postgres-db-volume:
  grafana_storage: { }
